{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning with VGG16 for Deep Space Object Classification\n",
    "\n"
   ],
   "metadata": {
    "id": "Jl9Sm_PVeh-2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "[**VGG16**](https://arxiv.org/pdf/1409.1556) is a convolutional neural network architecture with **16 layers** that are trainable (13 convolutional + 3 fully-connected). It was initially trained on the **[ImageNet](https://www.image-net.org/about.php)** dataset.\n",
    "\n",
    "\n",
    "In Transfer Learning, we take these pre-trained weights, which learned general image features, and reuse them for a new classification task on our own dataset. This approach usually speeds up training and can improve accuracy when the new dataset is smaller or less diverse than ImageNet."
   ],
   "metadata": {
    "id": "tw6nUYDoemG3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Add imports"
   ],
   "metadata": {
    "id": "F9q9D7K5fIyG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We import **TensorFlow(2.18.0) / Keras** for building and training. We use **matplotlib** for plotting metrics and **numpy** for numerical operations. 'preprocess_input' from VGG16 is used later to normalize images."
   ],
   "metadata": {
    "id": "52YnXgbPff09"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIFvhhqSeZQX",
    "outputId": "fe72fc00-6a53-430e-eb29-acfd2a69493c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Dataset"
   ],
   "metadata": {
    "id": "DnEKdJNLm0VB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, we will load our deep space objects dataset. It includes images from galaxies, nebulae, and star clusters. We will pull it from Google Drive, then split it into train, validation, and test sets. We will also apply basic preprocessing such as input resizing, normalization, etc."
   ],
   "metadata": {
    "id": "-Qy4sEbqm3_m"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Google Drive mounting\n"
   ],
   "metadata": {
    "id": "_3t2v2gPSat1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "66VsgaJhSgMd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Data splitting for Training and Validation"
   ],
   "metadata": {
    "id": "JaJQcc83nS2j"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first split our main dataset into training and validation subsets. This is done using the `validation_split` parameter in `ImageDataGenerator`, where 20% of the images from the dataset are reserved for validation."
   ],
   "metadata": {
    "id": "p3AtRLlWv5fe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_dir = '/content/drive/MyDrive/Transfer Learning in Astronomy/DATA_split/train'\n",
    "split_datagen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train_generator = split_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = split_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ],
   "metadata": {
    "id": "_YOsApPOnShb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "561eb445-6927-49ff-d3df-fd59b6bcc38e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Data Preprocessing"
   ],
   "metadata": {
    "id": "oY2kinh6x30L"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we apply preprocessing to the images so they match what VGG16 expects. The `preprocessing_function` parameter of the `ImageDataGenerator` lets us use the VGG16-specific `preprocess_input` function. This step normalizes the image pixel values (e.g., scaling and mean subtraction) to be consistent with the data on which VGG16 was originally trained."
   ],
   "metadata": {
    "id": "S0DYB19Ex7yC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_dataset_dir = '/content/drive/MyDrive/Transfer Learning in Astronomy/DATA_split/test'\n",
    "\n",
    "# Create an ImageDataGenerator for the test set with the VGG16 preprocessing function\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Generator for the test set\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,  # Important for evaluation to maintain order\n",
    "    classes=list(train_generator.class_indices.keys())\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BaBibrFfQ7x4",
    "outputId": "7d8991ff-c2e0-47c3-dc61-5629a41e8510"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Import VGG16 Model and Build the Classifier"
   ],
   "metadata": {
    "id": "Yzy2ViB8RJyf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Load and Inspect the VGG16 Architecture"
   ],
   "metadata": {
    "id": "uDH3RDnmRRjl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`include_top=False` removes the default classifier, allowing us to add our own layers tailored to our classification task."
   ],
   "metadata": {
    "id": "YnhbvoLaRgH3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.summary()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "TOH1clfdRT8o",
    "outputId": "cf2dcd32-01c5-47f2-c5bd-fa206eace6de"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 Freeze the Pre-Trained Layers"
   ],
   "metadata": {
    "id": "J0nWZt94Rl9X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "freezing the layers ensures that the pre-trained feature extraction remains intact during initial training."
   ],
   "metadata": {
    "id": "wDAF2agDRrMS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Freeze the layers of the VGG16 base model to preserve the pre-trained weights\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ],
   "metadata": {
    "id": "wld-ZXgeRoBl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 Build a New Classifier on Top"
   ],
   "metadata": {
    "id": "HOqfna-Sh9JB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Build a new classifier on top of the frozen VGG16 base\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "cBIKnpmph-Sz",
    "outputId": "bb07c4e1-bfb2-42ee-8dc3-bda16962c073"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Train the Model"
   ],
   "metadata": {
    "id": "0XAPbLj3Rya5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKZb-KK6R1pc",
    "outputId": "cf5fe4f3-7c44-4bd3-a0ec-67f56bb0f37e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Evaluate and Visualize the Model Performance"
   ],
   "metadata": {
    "id": "4B7skFA3R5Sr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 Plot Training Metrics"
   ],
   "metadata": {
    "id": "J3HkyP0KR9qx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "plBVYhgaR7pN",
    "outputId": "cd8111fc-d41d-4230-9d59-cc232affb96b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 Final Evaluation on the Test Set"
   ],
   "metadata": {
    "id": "9442ySzsSByq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9ron9owbSDPq",
    "outputId": "b62646ea-a0d5-4504-b8e5-ba21aef56956"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Predict a Specific Image"
   ],
   "metadata": {
    "id": "n2PLV91DSGHg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = 'img_path.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "predictions = model.predict(x)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "print(\"Predicted Class Index:\", predicted_class[0])"
   ],
   "metadata": {
    "id": "q6i21djMSHHO"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
